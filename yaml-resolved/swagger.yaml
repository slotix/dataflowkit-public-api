openapi: 3.0.0
info:
  title: Dataflow Kit Web Scraper
  description: |-
    Render Javascript driven pages, while we internally manage Headless Chrome and proxies for you.

    - Build a custom web scraper with our Visual point-and-click toolkit.
    - Scrape the most popular Search engines result pages (SERP).
    - Convert web pages to PDF and capture screenshots.

    Dataflow Kit API needs to be authenticated by passing a secret API Key to all API requests to the server as the `api_key` query parameter.
    The API Key can be found in the [DFK Dashboard](https://account.dataflowkit.com) after _free registration_.
  termsOfService: https://dataflowkit.com/terms
  contact:
    url: https://dataflowkit.com/
  version: "1.0"
servers:
- url: https://api.dataflowkit.com/v1
  description: Production server
security:
- ApiKeyAuth: []
tags:
- name: fetch
- name: serp
paths:
  /fetch:
    post:
      tags:
      - fetch
      summary: Download web page content
      description: |-
        Use fetch endpoint to download web pages.
        - _Base fetcher type_ is the right choice for fetching server-side rendered pages. It takes fewer resources and works faster than rendering HTML with _Chrome fetcher_
        - But for rendering Angular, React, and Vue.js web sites, you should always specify _Chrome fetcher type_. In this case, headless chrome fetcher renders dynamic Javascript content in the same way as real web browsers would do it.
      operationId: fetch
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/fetchrequest'
        required: true
      responses:
        "200":
          description: Returns utf8 encoded web page content.
          content:
            text/html; charset=utf-8:
              schema:
                type: string
              example: |-
                <html>
                    <head></head>
                    <body>{
                    &#34;ip&#34;: &#34;178.171.21.156&#34;,
                    &#34;city&#34;: &#34;Singapore&#34;,
                    &#34;region&#34;: null,
                    &#34;region_code&#34;: null,
                    &#34;country&#34;: &#34;SG&#34;,
                    &#34;country_code&#34;: &#34;SG&#34;,
                    &#34;country_code_iso3&#34;: &#34;SGP&#34;,
                    &#34;country_capital&#34;: &#34;Singapore&#34;,
                    &#34;country_tld&#34;: &#34;.sg&#34;,
                    &#34;country_name&#34;: &#34;Singapore&#34;,
                    &#34;continent_code&#34;: &#34;AS&#34;,
                    &#34;in_eu&#34;: false,
                    &#34;postal&#34;: &#34;18&#34;,
                    &#34;latitude&#34;: 1.2929,
                    &#34;longitude&#34;: 103.8547,
                    &#34;timezone&#34;: &#34;Asia/Singapore&#34;,
                    &#34;utc_offset&#34;: &#34;+0800&#34;,
                    &#34;country_calling_code&#34;: &#34;+65&#34;,
                    &#34;currency&#34;: &#34;SGD&#34;,
                    &#34;currency_name&#34;: &#34;Dollar&#34;,
                    &#34;languages&#34;: &#34;cmn,en-SG,ms-SG,ta-SG,zh-SG&#34;,
                    &#34;country_area&#34;: 692.7,
                    &#34;country_population&#34;: 4701069.0,
                    &#34;asn&#34;: &#34;AS9009&#34;,
                    &#34;org&#34;: &#34;M247 Ltd&#34;
                }</body>
                </html>
      deprecated: false
  /serp:
    post:
      tags:
      - serp
      summary: Collect search results from search engines
      description: |-
        To crawl search engine result pages, you can use `/serp` endpoint. SERP collection service extracts a list of organic results, news, images, and more.  Specify configuration parameters, such as country or languages, to customize output SERP data.
        The following search engines are supported
        - google
        - google-image
        - google-news
        - google-shopping
        - bing
        - duckduckgo
        - baidu
        - yandex

        <h2>Search parameters</h2>

        > In most cases, you don't need to customize parameters by hand. Use <a href="https://dataflowkit.com/serp" target="_blank">SERP extraction Code generator</a>. It is the easiest way to generate a payload for launching in the Dataflow kit cloud.

        <h3>URL GET parameters</h3>

        ||||
        |-|-|-|
        |q| Parameter defines encoded search term. You can use anything that you would use in a regular Search engines search. (e.g. for Google, <ul> <li><code>link:dataflowkit.com</code>,</li> <li><code>site:twitter.com Bratislava</code>,</li><li><code>inurl:view/view.shtml</code>, etc.)</li></ul> See The Complete List of 42 Advanced <a href="https://ahrefs.com/blog/google-advanced-search-operators/" target="_blank">Google Search Operators</a>|<ul> <li><code>q</code> parameter is used by google, Bing, DuckDuckGo.</li><li> <code>text</code> is used as query holder by Yandex SE.</li><li> Chineese Baidu uses <code>wd</code> for this purpose.</li></ul>|
        |tbm| <code>tbm</code> is a special Google parameter used to differentiate between search types| <ul> <li><code>tbm=isch</code> - Google Images,</li> <li> <code>tbm=nws</code> - Google News</li> <li><code>tbm=shop</code> - Google Shopping</li> </ul>|
        |lr|Restricts the search to documents written in a particular languages.|<ul><li>Google uses <code>lang_{two-letter lang code}</code> to specify languages and <code>&#124;</code> as a delimiter. (e.g., <code>lang_sk&#124;lang_de</code> will only search Slovak and German pages). See the <a href="https://developers.google.com/custom-search/v1/cse/list">full list</a> of possible values for Google. </li><li>For Bing specify <code>setLang=en</code> parameter.</li><li> In Yandex use <code>lang=ca</code> parameter</li></ul>|
        |gl|Specify the country to search from. It's a two-letter country code. (e.g., <code>sk</code> for Slovakia, or <code>us</code> for the United States).| For Google see the <a href="https://developers.google.com/custom-search/docs/xml_results_appendices#countryCodes">Country Codes</a> page for a list of valid values. For Bing <code>cc=at</code> parameter is used.|
      operationId: serp
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/serprequest'
        required: true
      responses:
        "200":
          description: Returns data in the one of the follwing formats - JSON, JSON
            Lines, CSV, MS Excel, XML
          content:
            application/json:
              schema:
                type: object
              example:
              - description_text: Dataflow kit visits the web on your behalf, processes
                  Javascript driven pages in the cloud, return rendered HTML, capture
                  screenshot or save as PDF. Dataflow Kit services. Headless Chrome
                  as a service. We automate dynamic web content download using the
                  Headless Chrome browser. ...
                link_href: https://dataflowkit.com/
                link_text: Turn Websites into structured data /Dataflow kit
              - description_text: Dataflow kit ("DFK") is a Web Scraping framework
                  for Gophers. It extracts data from web pages, following the specified
                  CSS Selectors. You can use it in many ways for data mining, data
                  processing or archiving.
                link_href: https://github.com/slotix/dataflowkit
                link_text: 'GitHub - slotix/dataflowkit: Extract structured data from
                  ...'
              - description_text: The Department of Health - Abu Dhabi (DoH - Abu
                  Dhabi) leverages the DataFlow Group's specialized Primary Source
                  Verification (PSV) solutions to screen the credentials of professionals
                  working within Abu Dhabi's healthcare sector. As the regulative
                  body of the healthcare sector in Abu Dhabi, DoH - Abu Dhabi ensures
                  excellence for the ...
                link_href: https://corp.dataflowgroup.com/verification-services/start-your-verification/healthcare/department-of-health-abu-dhabi/
                link_text: Department of Health - Abu Dhabi - Dataflow Group
              - description_text: Dataflow Kit was added by slotix in Apr 2020 and
                  the latest update was made in May 2020. The list of alternatives
                  was updated Apr 2020. It's possible to update the information on
                  Dataflow Kit or report it as discontinued, duplicated or spam.
                link_href: https://alternativeto.net/software/dataflow-kit/
                link_text: Dataflow Kit Alternatives and Similar Websites and Apps
                  ...
              - description_text: Dataflow Kit Reloaded. We are so excited to introduce
                  a new, completely re-implemented Dataflow Kit. In particular, we
                  supplement our legacy custom web scraper with more focused and more
                  understandable web services for our users.
                link_href: https://blog.dataflowkit.com/
                link_text: Dataflow Kit Blog
              - description_text: The Dubai Health Authority (DHA) leverages the DataFlow
                  Group's specialized Primary Source Verification (PSV) solutions
                  to screen the credentials of professionals working within Dubai's
                  healthcare sector. The DHA is led by a mission to ensure access
                  to health services, maintain and enhance the quality of these services,
                  improve the health ...
                link_href: https://corp.dataflowgroup.com/verification-services/start-your-verification/healthcare/dubai-health-authority/
                link_text: Dubai Health Authority - Dataflow Group
              - description_text: Dataflow Kit Reloaded. We are so excited to introduce
                  a new, completely re-implemented Dataflow Kit. In particular, we
                  supplement our legacy custom web scraper with more focused and more
                  understandable web services for our users.
                link_href: https://blog.dataflowkit.com/reloaded/
                link_text: Dataflow Kit Reloaded.
              - description_text: The Dataflow Kit API allows embedding free COVID-19
                  live statistics web widget into sites. Methods provide data for
                  the USA, Spain, or the World. Developers can access live statistics
                  data through the DFK COVID-19 API for free. They can build widgets,
                  mobile apps, or integrate them into other applications.
                link_href: https://www.programmableweb.com/api/dataflow-kit-rest-api-v1
                link_text: Dataflow Kit REST API v1 | ProgrammableWeb
              - description_text: Description. Dataflow kit is a Scraping framework
                  for Gophers. DFK extracts structured data from web pages, following
                  the specified extractors. It can be used in many ways for data mining,
                  data processing or archiving.
                link_href: https://go.libhunt.com/dataflowkit-alternatives
                link_text: Dataflow kit Alternatives - Go Text Processing | LibHunt
              - description_text: Point, click and extract. Work on any interactive
                  site Scrape a website behind a login form Extract data from multiple
                  pages. Scrape infinite scrolled pages. Crawl details; Extract and
                  follow lin
                link_href: https://www.startupranking.com/dataflow-kit
                link_text: Dataflow Kit - Fast extraction of structured data from
                  ...
      deprecated: false
  /parse:
    post:
      tags:
      - parse
      summary: Extract structured data from web pages
      description: |-
        Dataflow kit uses CSS selectors to find HTML elements in web pages for later data extraction.

        Open [visual point-and-click toolkit](https://dataflowkit.com/dfk) and click desired elements on a page to specify extracting data.

        Then you can send generated payload to `/parse` endpoint. We crawl web pages and extract data like text, links, or images for you following the specified rules.

        Extracted data is returned in CSV, MS Excel, JSON, JSON(Lines) or XML format.
        <h2>Chaining</h2>

        List pages have links to detail pages having more data. You can use chaining functionality of prowebscraper which can help you to retrieve all the detail page data at the same time.
      operationId: parse
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/parserequest'
        required: true
      responses:
        "200":
          description: Returns data in the one of the follwing formats - JSON, JSON
            Lines, CSV, MS Excel, XML
          content:
            application/json:
              schema:
                type: object
              example:
              - Name_href: https://test.dataflowkit.com/persons/1
                Name_text: Ethan Aguirre
                Number_text: "1"
                Picture_alt: ""
                Picture_src: https://test.dataflowkit.com/static/img/avataaars-1.svg
              - Name_href: https://test.dataflowkit.com/persons/2
                Name_text: Melodie Holder
                Number_text: "2"
                Picture_alt: ""
                Picture_src: https://test.dataflowkit.com/static/img/avataaars-2.svg
              - Name_href: https://test.dataflowkit.com/persons/3
                Name_text: Meghan Reyes
                Number_text: "3"
                Picture_alt: ""
                Picture_src: https://test.dataflowkit.com/static/img/avataaars-3.svg
              - Name_href: https://test.dataflowkit.com/persons/4
                Name_text: Lane Vinson
                Number_text: "4"
                Picture_alt: ""
                Picture_src: https://test.dataflowkit.com/static/img/avataaars-4.svg
              - Name_href: https://test.dataflowkit.com/persons/5
                Name_text: Philip Tillman
                Number_text: "5"
                Picture_alt: ""
                Picture_src: https://test.dataflowkit.com/static/img/avataaars-5.svg
              - Name_href: https://test.dataflowkit.com/persons/6
                Name_text: Theodore Mcclain
                Number_text: "6"
                Picture_alt: ""
                Picture_src: https://test.dataflowkit.com/static/img/avataaars-6.svg
              - Name_href: https://test.dataflowkit.com/persons/7
                Name_text: Neville Kane
                Number_text: "7"
                Picture_alt: ""
                Picture_src: https://test.dataflowkit.com/static/img/avataaars-7.svg
              - Name_href: https://test.dataflowkit.com/persons/8
                Name_text: Lila Vazquez
                Number_text: "8"
                Picture_alt: ""
                Picture_src: https://test.dataflowkit.com/static/img/avataaars-8.svg
              - Name_href: https://test.dataflowkit.com/persons/9
                Name_text: Ulysses Peters
                Number_text: "9"
                Picture_alt: ""
                Picture_src: https://test.dataflowkit.com/static/img/avataaars-9.svg
              - Name_href: https://test.dataflowkit.com/persons/10
                Name_text: Camden Young
                Number_text: "10"
                Picture_alt: ""
                Picture_src: https://test.dataflowkit.com/static/img/avataaars-10.svg
              - Name_href: https://test.dataflowkit.com/persons/1
                Name_text: Ethan Aguirre
                Number_text: "1"
                Picture_alt: ""
                Picture_src: https://test.dataflowkit.com/static/img/avataaars-1.svg
              - Name_href: https://test.dataflowkit.com/persons/2
                Name_text: Melodie Holder
                Number_text: "2"
                Picture_alt: ""
                Picture_src: https://test.dataflowkit.com/static/img/avataaars-2.svg
              - Name_href: https://test.dataflowkit.com/persons/3
                Name_text: Meghan Reyes
                Number_text: "3"
                Picture_alt: ""
                Picture_src: https://test.dataflowkit.com/static/img/avataaars-3.svg
              - Name_href: https://test.dataflowkit.com/persons/4
                Name_text: Lane Vinson
                Number_text: "4"
                Picture_alt: ""
                Picture_src: https://test.dataflowkit.com/static/img/avataaars-4.svg
              - Name_href: https://test.dataflowkit.com/persons/5
                Name_text: Philip Tillman
                Number_text: "5"
                Picture_alt: ""
                Picture_src: https://test.dataflowkit.com/static/img/avataaars-5.svg
              - Name_href: https://test.dataflowkit.com/persons/6
                Name_text: Theodore Mcclain
                Number_text: "6"
                Picture_alt: ""
                Picture_src: https://test.dataflowkit.com/static/img/avataaars-6.svg
              - Name_href: https://test.dataflowkit.com/persons/7
                Name_text: Neville Kane
                Number_text: "7"
                Picture_alt: ""
                Picture_src: https://test.dataflowkit.com/static/img/avataaars-7.svg
              - Name_href: https://test.dataflowkit.com/persons/8
                Name_text: Lila Vazquez
                Number_text: "8"
                Picture_alt: ""
                Picture_src: https://test.dataflowkit.com/static/img/avataaars-8.svg
              - Name_href: https://test.dataflowkit.com/persons/9
                Name_text: Ulysses Peters
                Number_text: "9"
                Picture_alt: ""
                Picture_src: https://test.dataflowkit.com/static/img/avataaars-9.svg
              - Name_href: https://test.dataflowkit.com/persons/10
                Name_text: Camden Young
                Number_text: "10"
                Picture_alt: ""
                Picture_src: https://test.dataflowkit.com/static/img/avataaars-10.svg
      deprecated: false
components:
  schemas:
    fetchrequest:
      title: Fetch request
      required:
      - type
      - url
      type: object
      properties:
        url:
          type: string
          description: Specify URL to download.
        type:
          type: string
          description: If set to `base`, the Base fetcher is used for downloading
            web page content. Use `chrome` for fetching content with a Headless chrome
            browser. If omitted `base` fetcher is used by default.
          enum:
          - base
          - chrome
        proxy:
          type: string
          description: Specify proxy by adding [country ISO code](https://en.wikipedia.org/wiki/ISO_3166-2)
            to `country-` value to send requests through a proxy in the specified
            country. Use `country-any` to use random geo-targets.
          example: country-sk
        waitDelay:
          type: number
          description: Specify a wait delay (in seconds). This may be useful if certain
            elements of the web site need to be rendered after the initial page load.
            _(Chrome fetcher type only)_
        actions:
          type: array
          description: Use actions to automate manual workflows while rendering web
            pages. They simulate real-world human interaction with pages. _(Chrome
            fetcher type only)_
          items:
            $ref: '#/components/schemas/action'
          default: []
      example:
        proxy: country-any
        type: base
        url: https://ipapi.co/json/
        actions:
        - waitFor:
            waitForSelector: :root
    serprequest:
      title: SERP request
      required:
      - format
      - name
      - proxy
      - type
      - url
      type: object
      properties:
        name:
          type: string
          description: Collection name.
        url:
          type: string
          description: url holds the link to a Search Engine to use, and other optional
            parameters like languages or country.
        type:
          type: string
          description: For SERP requests you should _always_ use `chrome` type to
            fetch content with a Headless chrome browser
          example: chrome
        proxy:
          type: string
          description: Always specify proxy for sending SERP requests. Add choosen
            [country ISO code](https://en.wikipedia.org/wiki/ISO_3166-2) to `country-`
            value to send requests through a proxy in the specified country. Use `country-any`
            to use random geo-targets.
          example: country-any
      example:
        name: duckduckgo
        request:
          url: https://duckduckgo.com/?q=Dataflow+kit&ia=web
          proxy: country-any
          type: chrome
        fields:
        - name: link
          selector: .result__a
          attrs:
          - href
          - text
          type: 2
          filters:
          - name: trim
        - name: description
          selector: .js-result-snippet
          attrs:
          - text
          type: 1
          filters:
          - name: trim
        commonParent: div[id].result
        format: json
    parserequest:
      title: Data Extraction request
      required:
      - fields
      - format
      - name
      - proxy
      - type
      - url
      type: object
      properties:
        name:
          type: string
          description: Collection name.
        request:
          $ref: '#/components/schemas/fetchrequest'
        commonParent:
          type: string
          description: Specifies common ancestor block for a set of fields used to
            extract data from a web page. _(CSS Selector)_
          example: .common-block
        fields:
          type: array
          description: Define a  set of fields used to extract data from a web page.
            A Field represents a given chunk of extracted data from every block on
            each page.
          items:
            $ref: '#/components/schemas/field'
        paginator:
          $ref: '#/components/schemas/Paginator'
        path:
          title: Path
          type: boolean
          description: Path is a special parameter specifying navigation pages only.
            It collects information from detailed pages. No results from the current
            page return. Defaults to false.
          default: false
        format:
          title: Format
          type: string
          description: Extracted data is returned either in CSV, MS Excel, JSON, JSON(Lines)
            or XML format.
          enum:
          - csv
          - json
          - jsonl
          - excel
          - xml
      example:
        name: test.dataflowkit.com
        request:
          url: https://test.dataflowkit.com/persons/page-0
          type: chrome
          proxy: country-any
        fields:
        - name: Number
          selector: .badge-primary
          attrs:
          - text
          type: 1
          filters:
          - name: trim
        - name: Name
          selector: '#cards a'
          attrs:
          - href
          - text
          type: 2
          filters:
          - name: trim
        - name: Picture
          selector: .card-img-top
          attrs:
          - src
          - alt
          type: 0
          filters:
          - name: trim
        paginator:
          nextPageSelector: .page-link
          pageNum: 2
        path: false
        format: json
    field:
      required:
      - attrs
      - name
      - selector
      - type
      type: object
      properties:
        name:
          type: string
          description: Field name is used to aggregate results.
        selector:
          type: string
          description: Selector represents a CSS selector for data extraction within
            the given block.
          example: '#cards a'
        type:
          type: integer
          description: Selector type. ( 0 - image, 1 - text, 2 - link)
          enum:
          - 0
          - 1
          - 2
        attrs:
          type: array
          description: A set of attributes to extract from a Field. Find more information
            about attributes
          items:
            type: string
            enum:
            - text
            - href
            - src
            - alt
        filters:
          type: array
          description: Filters are used to pre-processing of text data when extracting.
          items:
            anyOf:
            - type: object
              properties:
                name:
                  type: string
                  enum:
                  - trim
                  - normal
                  - uppercase
                  - lowercase
                  - capitalize
                  - concatinate
            - type: object
              properties:
                name:
                  type: string
                  example: regex
                param:
                  type: string
                  example: '[\\d.]+'
        details:
          description: Details themself represent independent Data Extraction request
            that extracts data from linked pages.
          allOf:
          - $ref: '#/components/schemas/parserequest'
    action:
      title: Action
      type: object
      anyOf:
      - $ref: '#/components/schemas/input'
      - $ref: '#/components/schemas/click'
      - $ref: '#/components/schemas/waitFor'
      - $ref: '#/components/schemas/scroll'
    input:
      title: Input action
      type: object
      properties:
        inputSelector:
          type: string
          example: '#search-form-editbox'
        inputText:
          type: string
          example: dataflow kit
      description: Specify `Input CSS Selector` and `Input Text` to perform search
        queries, or fill forms.
    click:
      title: Click action
      type: object
      properties:
        clickSelector:
          type: string
          example: .click-me
      description: Click on an element with the specified `CSS Selector`.
    waitFor:
      title: Wait for action
      type: object
      properties:
        waitForSelector:
          type: string
          example: :root
      description: Wait for the specific DOM elements you want to manipulate.
    scroll:
      title: Scroll action
      type: object
      properties:
        paginate:
          type: integer
          example: 3
        element:
          type: string
          example: .page-link
      description: Scroll a page down to load more content, simulating user interaction
        with infinite scrolled pages. Or specify the element's CSS Selector to click
        for loading more content.
    Paginator:
      type: object
      properties:
        nextPageSelector:
          type: string
          example: .page-link
        pageNum:
          type: integer
          example: 10
      description: Specify _Next link_ paginator on pages containing a link pointing
        to the next page. The next page link is extracted from a document by querying
        href attribute of a given element's CSS selector.
  securitySchemes:
    ApiKeyAuth:
      type: apiKey
      name: api_key
      in: query
